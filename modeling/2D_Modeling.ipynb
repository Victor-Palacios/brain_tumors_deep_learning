{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\n\n# data augmentation\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# pretrained models\nimport torchvision\nfrom torchvision import models, transforms\n\nimport os\nimport json\nimport glob\nimport random\nimport collections\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-11T00:11:27.005273Z","iopub.execute_input":"2021-08-11T00:11:27.005695Z","iopub.status.idle":"2021-08-11T00:11:30.583925Z","shell.execute_reply.started":"2021-08-11T00:11:27.005605Z","shell.execute_reply":"2021-08-11T00:11:30.582970Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def one_pass(model, dataloader, optimizer, lossFun, backwards=True, print_loss=False):\n    \n    if backwards == True:\n        model.train()\n    else:\n        model.eval()\n    \n    total_loss = 0.0\n    for x, y in tqdm(dataloader):\n        \n        y_pred = model(x)\n        y_pred = torch.sigmoid(y_pred).squeeze()\n        loss = lossFun(y_pred, y.float())\n        total_loss += loss.item()\n        \n        if backwards == True:\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n    avg_loss = total_loss / len(dataloader)\n    \n    if print_loss == True:\n        print(avg_loss)\n    \n    return avg_loss\n\ndef one_pass_acc(model, dataloader, num_points):\n    model.eval()\n    total_incorrect = 0\n        \n    for x, y in dataloader:\n        y_pred = model(x)\n        y_pred = torch.sigmoid(y_pred).squeeze()\n        y_pred = (y_pred > 0.5).int()\n        \n        total_incorrect += torch.count_nonzero(y - y_pred).item()\n        \n    percent_wrong = total_incorrect / num_points\n    return 1 - percent_wrong","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:11:30.585298Z","iopub.execute_input":"2021-08-11T00:11:30.585583Z","iopub.status.idle":"2021-08-11T00:11:30.594248Z","shell.execute_reply.started":"2021-08-11T00:11:30.585555Z","shell.execute_reply":"2021-08-11T00:11:30.593438Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class AnimalFacesDataset(Dataset):\n    def __init__(self, df, augment=False):\n        self.df = df\n        self.augment = augment\n                \n        # define the transformation\n        if augment == True:\n            self.transforms = A.Compose([\n                # spatial transforms\n                A.RandomCrop(width=224, height=224),\n                A.HorizontalFlip(p=.5),\n                A.VerticalFlip(p=.5),\n                A.Rotate(limit = 10, \n                         border_mode = cv2.BORDER_CONSTANT, \n                         value = 0.0, p = .75),\n                \n                # pixel-level transformation\n                A.RandomBrightnessContrast(p=0.5),\n                \n                # we will normalize according to ImageNet since we will be using a pre-trained ResNet\n                # this adjusts from [0,255] to [0,1]\n                #A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n                \n                # convert to a tensor and move color channels\n                ToTensorV2()\n            ])\n        else:\n            self.transforms = A.Compose([\n                # training/valid images have same size\n                A.CenterCrop(width=224, height=224),\n                \n                # normalize\n                #A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n                \n                # convert to a tensor and move color channels\n                ToTensorV2()\n            ])\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # get ingredients for retrieving image\n        image_path = row['resized_location']\n        \n        # read the img\n        img = np.load(image_path)\n                \n        # transform the image\n        # certain transformations expect the uint8 datatype\n        transformed = self.transforms(image=img.astype(np.uint8))\n        img = transformed['image']\n        img = img/255\n        \n        label = torch.tensor(row['MGMT_value'])\n        \n        return img, label","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:11:30.595796Z","iopub.execute_input":"2021-08-11T00:11:30.596223Z","iopub.status.idle":"2021-08-11T00:11:30.607989Z","shell.execute_reply.started":"2021-08-11T00:11:30.596194Z","shell.execute_reply":"2021-08-11T00:11:30.606906Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"alexnet_frozen = models.alexnet(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:11:30.609673Z","iopub.execute_input":"2021-08-11T00:11:30.610088Z","iopub.status.idle":"2021-08-11T00:11:47.688183Z","shell.execute_reply.started":"2021-08-11T00:11:30.610047Z","shell.execute_reply":"2021-08-11T00:11:47.687156Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/233M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49074b6d1c5147ea96c31db2941b6a60"}},"metadata":{}}]},{"cell_type":"code","source":"alexnet_frozen.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:11:47.689233Z","iopub.execute_input":"2021-08-11T00:11:47.689505Z","iopub.status.idle":"2021-08-11T00:11:47.694861Z","shell.execute_reply.started":"2021-08-11T00:11:47.689479Z","shell.execute_reply":"2021-08-11T00:11:47.693835Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"alexnet_frozen","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:11:47.696015Z","iopub.execute_input":"2021-08-11T00:11:47.696281Z","iopub.status.idle":"2021-08-11T00:11:47.713380Z","shell.execute_reply.started":"2021-08-11T00:11:47.696256Z","shell.execute_reply":"2021-08-11T00:11:47.712212Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"%%time\ntrain_df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\ntrain_planes = pd.read_csv(\"../input/train-cleanedcsv/train_cleaned.csv\", index_col=0)\nmid_pics = []\nfor patient in train_df.BraTS21ID:\n    try:\n        pic = round(train_planes[(train_planes.patient == patient) & \n                     (train_planes.modality == \"T1w\") &\n                     (train_planes.plane == \"axial\")][\"image_id\"].median())\n        mid_pics.append(pic)\n    except:\n        mid_pics.append(-1)\n\nt1_train = train_df.copy()\nt1_train[\"pic_id\"] = mid_pics\nt1_train = t1_train[t1_train.pic_id != -1]","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:11:47.715095Z","iopub.execute_input":"2021-08-11T00:11:47.715468Z","iopub.status.idle":"2021-08-11T00:12:16.650131Z","shell.execute_reply.started":"2021-08-11T00:11:47.715428Z","shell.execute_reply":"2021-08-11T00:12:16.649231Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"CPU times: user 28.3 s, sys: 130 ms, total: 28.4 s\nWall time: 28.9 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nt1_train = t1_train.reset_index(drop=True)\nt1_train[\"BraTS21ID\"] = t1_train.BraTS21ID.astype(str).str.zfill(5)\n\ndef resize_img(image, resized_image_location, size):\n    img = cv2.resize(image, size)\n    np.save(resized_image_location, img)\n    \ndef load_dicom(path):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\nresized = []\nfor patient in t1_train.BraTS21ID:\n    pic = t1_train[t1_train.BraTS21ID==patient].pic_id.values[0]\n    \n    original_image_location = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/{patient}/T1w/Image-{pic}.dcm\"\n    resized_image_location = f\"./{patient}_{pic}.npy\"\n    resized.append(resized_image_location)\n    \n    image = load_dicom(original_image_location)\n    resize_img(image, resized_image_location, (256, 256))\n\nt1_train[\"resized_location\"] = resized\nt1_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:12:16.652057Z","iopub.execute_input":"2021-08-11T00:12:16.652346Z","iopub.status.idle":"2021-08-11T00:12:25.130677Z","shell.execute_reply.started":"2021-08-11T00:12:16.652310Z","shell.execute_reply":"2021-08-11T00:12:25.129646Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"CPU times: user 2.05 s, sys: 317 ms, total: 2.37 s\nWall time: 8.46 s\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"  BraTS21ID  MGMT_value  pic_id resized_location\n0     00000           1      17   ./00000_17.npy\n1     00002           1      16   ./00002_16.npy\n2     00003           0      17   ./00003_17.npy\n3     00005           1      14   ./00005_14.npy\n4     00006           1      16   ./00006_16.npy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BraTS21ID</th>\n      <th>MGMT_value</th>\n      <th>pic_id</th>\n      <th>resized_location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000</td>\n      <td>1</td>\n      <td>17</td>\n      <td>./00000_17.npy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00002</td>\n      <td>1</td>\n      <td>16</td>\n      <td>./00002_16.npy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00003</td>\n      <td>0</td>\n      <td>17</td>\n      <td>./00003_17.npy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00005</td>\n      <td>1</td>\n      <td>14</td>\n      <td>./00005_14.npy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00006</td>\n      <td>1</td>\n      <td>16</td>\n      <td>./00006_16.npy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"t1_train.tail(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:12:25.132147Z","iopub.execute_input":"2021-08-11T00:12:25.132391Z","iopub.status.idle":"2021-08-11T00:12:25.143565Z","shell.execute_reply.started":"2021-08-11T00:12:25.132367Z","shell.execute_reply":"2021-08-11T00:12:25.142685Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"    BraTS21ID  MGMT_value  pic_id resized_location\n562     01005           1      12   ./01005_12.npy\n563     01007           1      62   ./01007_62.npy\n564     01008           1      96   ./01008_96.npy\n565     01009           0      12   ./01009_12.npy\n566     01010           0      96   ./01010_96.npy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BraTS21ID</th>\n      <th>MGMT_value</th>\n      <th>pic_id</th>\n      <th>resized_location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>562</th>\n      <td>01005</td>\n      <td>1</td>\n      <td>12</td>\n      <td>./01005_12.npy</td>\n    </tr>\n    <tr>\n      <th>563</th>\n      <td>01007</td>\n      <td>1</td>\n      <td>62</td>\n      <td>./01007_62.npy</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>01008</td>\n      <td>1</td>\n      <td>96</td>\n      <td>./01008_96.npy</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>01009</td>\n      <td>0</td>\n      <td>12</td>\n      <td>./01009_12.npy</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>01010</td>\n      <td>0</td>\n      <td>96</td>\n      <td>./01010_96.npy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"t1_train = t1_train.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:12:25.144738Z","iopub.execute_input":"2021-08-11T00:12:25.145072Z","iopub.status.idle":"2021-08-11T00:12:25.149559Z","shell.execute_reply.started":"2021-08-11T00:12:25.145041Z","shell.execute_reply":"2021-08-11T00:12:25.148751Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"ds_train = AnimalFacesDataset(t1_train, augment=True)\ndl_train = DataLoader(ds_train, batch_size=50, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:12:25.150458Z","iopub.execute_input":"2021-08-11T00:12:25.150746Z","iopub.status.idle":"2021-08-11T00:12:25.161755Z","shell.execute_reply.started":"2021-08-11T00:12:25.150698Z","shell.execute_reply":"2021-08-11T00:12:25.161014Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# to confirm everything was loaded correctly\nprint(len(ds_train))\nfor idx, (tensor, output) in enumerate(ds_train):\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:12:25.164513Z","iopub.execute_input":"2021-08-11T00:12:25.164782Z","iopub.status.idle":"2021-08-11T00:12:25.912486Z","shell.execute_reply.started":"2021-08-11T00:12:25.164758Z","shell.execute_reply":"2021-08-11T00:12:25.911585Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"567\n","output_type":"stream"}]},{"cell_type":"code","source":"# turn off gradients for all the parameters in frozen\nfor param in alexnet_frozen.parameters():\n            param.requires_grad = False\n\n# re-intialize the last layer for our task\nalexnet_frozen.classifier[6] = nn.Linear(4096, 1)\n\n# pass the appropriate parameters to the optimizer\nparams_to_update = []\n\nfor param in alexnet_frozen.parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n\noptimizer = optim.Adam(params_to_update, lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:12:25.913713Z","iopub.execute_input":"2021-08-11T00:12:25.914256Z","iopub.status.idle":"2021-08-11T00:12:25.920998Z","shell.execute_reply.started":"2021-08-11T00:12:25.914221Z","shell.execute_reply":"2021-08-11T00:12:25.920316Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"next(iter(ds_train))[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:12:25.922194Z","iopub.execute_input":"2021-08-11T00:12:25.922755Z","iopub.status.idle":"2021-08-11T00:12:25.971734Z","shell.execute_reply.started":"2021-08-11T00:12:25.922702Z","shell.execute_reply":"2021-08-11T00:12:25.971099Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"tensor([[[0.1059, 0.1059, 0.1059,  ..., 0.1059, 0.1059, 0.1059],\n         [0.1059, 0.1059, 0.1059,  ..., 0.1059, 0.1059, 0.1059],\n         [0.1059, 0.1059, 0.1059,  ..., 0.1059, 0.1059, 0.1059],\n         ...,\n         [0.1059, 0.1059, 0.1059,  ..., 0.1059, 0.1059, 0.1059],\n         [0.1059, 0.1059, 0.1059,  ..., 0.1059, 0.1059, 0.1059],\n         [0.1059, 0.1059, 0.1059,  ..., 0.1059, 0.1059, 0.1059]]])"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = alexnet_frozen(next(iter(dl_train))[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:12:25.972811Z","iopub.execute_input":"2021-08-11T00:12:25.973192Z","iopub.status.idle":"2021-08-11T00:12:26.790634Z","shell.execute_reply.started":"2021-08-11T00:12:25.973152Z","shell.execute_reply":"2021-08-11T00:12:26.789572Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"lossFun = nn.BCELoss()\n\nnum_epochs = 10\ntrain_losses = []\n\nfor epoch in tqdm(range(num_epochs)):\n    print('Epoch: ', epoch)\n    \n    train_loss = one_pass(alexnet_frozen, dl_train, optimizer, lossFun)\n    train_losses.append(train_loss)\n    print('Train loss: ', train_loss)\n        \n    train_acc = one_pass_acc(alexnet_frozen, dl_train, len(ds_train))\n    print('Train Acc: ', train_acc)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T00:12:26.791873Z","iopub.execute_input":"2021-08-11T00:12:26.792263Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"196bc0f07946439dbe02056da95daff7"}},"metadata":{}},{"name":"stdout","text":"Epoch:  0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"878a15aa0c1548e3a557cc021c1aa46e"}},"metadata":{}},{"name":"stdout","text":"Train loss:  0.7236275424559911\nTrain Acc:  0.5291005291005291\nEpoch:  1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"373f87d7594f4d849c077c75349981e7"}},"metadata":{}},{"name":"stdout","text":"Train loss:  0.7317943771680196\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}